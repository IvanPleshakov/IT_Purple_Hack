{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7bef09-9e86-4b19-bbb7-e0ccb7515328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T22:50:38.627643Z",
     "iopub.status.busy": "2024-02-14T22:50:38.627255Z",
     "iopub.status.idle": "2024-02-14T22:50:39.496067Z",
     "shell.execute_reply": "2024-02-14T22:50:39.495215Z",
     "shell.execute_reply.started": "2024-02-14T22:50:38.627616Z"
    },
    "id": "8b7bef09-9e86-4b19-bbb7-e0ccb7515328",
    "tags": []
   },
   "source": [
    "# KMeans and MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ddb399-18f4-4051-86c0-39f1c623eef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T11:34:39.109032Z",
     "iopub.status.busy": "2024-02-15T11:34:39.108624Z",
     "iopub.status.idle": "2024-02-15T11:34:39.955360Z",
     "shell.execute_reply": "2024-02-15T11:34:39.954584Z",
     "shell.execute_reply.started": "2024-02-15T11:34:39.109007Z"
    },
    "id": "e0ddb399-18f4-4051-86c0-39f1c623eef5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "RANDOM_STATE = 560\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf3aae-5417-42a3-9ed2-818b9aef0f2f",
   "metadata": {
    "id": "cbcf3aae-5417-42a3-9ed2-818b9aef0f2f"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64dda0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top_cats(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    column: str,\n",
    "    top_k: int,\n",
    "    inplace: bool = False,\n",
    "):\n",
    "    if not inplace:\n",
    "        train_df = train_df.copy()\n",
    "        test_df = test_df.copy()\n",
    "\n",
    "    top = train_df[column].value_counts().nlargest(top_k).index\n",
    "    train_mask = train_df[column].isin(top) + train_df[column].isna()\n",
    "    test_mask = test_df[column].isin(top) + test_df[column].isna()\n",
    "    train_df[column] = train_df[column].where(train_mask, \"other\")\n",
    "    test_df[column] = test_df[column].where(test_mask, \"other\")\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c8b1b0-f95e-4cb5-bbc1-c0edb76568c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T11:34:44.750723Z",
     "iopub.status.busy": "2024-02-15T11:34:44.750145Z",
     "iopub.status.idle": "2024-02-15T11:34:46.098228Z",
     "shell.execute_reply": "2024-02-15T11:34:46.097494Z",
     "shell.execute_reply.started": "2024-02-15T11:34:44.750694Z"
    },
    "id": "32c8b1b0-f95e-4cb5-bbc1-c0edb76568c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/train_data.pqt\")\n",
    "test_df = pd.read_parquet(\"data/test_data_filled.pqt\")\n",
    "target = \"end_cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be5c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_ae, test_for_ae = left_top_cats(train_df, test_df, \"index_city_code\", 40)\n",
    "left_top_cats(train_for_ae, test_for_ae, \"channel_code\", 15, inplace=True)\n",
    "left_top_cats(train_for_ae, test_for_ae, \"okved\", 30, inplace=True)\n",
    "left_top_cats(train_for_ae, test_for_ae, \"city\", 40, inplace=True)\n",
    "\n",
    "# датасеты для автоэнкодера, final_embeds получаем после прогона ае по этим датасетам\n",
    "train_for_ae.to_parquet(\"data/train_ae_v.pqt\")\n",
    "test_for_ae.to_parquet(\"data/test_ae_v.pqt\")\n",
    "\n",
    "del train_for_ae, test_for_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e9a6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890120, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = np.load(\"final_embeds.npy\").astype(np.float32)\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32ff3b",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_embeds = (\n",
    "    torch.from_numpy(feats[:600000])\n",
    "    .to(DEVICE)\n",
    "    .reshape(-1, 3, feats.shape[1])\n",
    "    .mean(1)\n",
    "    .cpu()\n",
    "    .numpy()\n",
    ")\n",
    "\n",
    "test_df_w_embeds = test_df[[\"id\"]].copy()\n",
    "test_df_w_embeds[[f\"e_{i}\" for i in range(feats.shape[1])]] = feats[600000:]\n",
    "test_df_w_embeds = test_df_w_embeds.copy()\n",
    "test_df_w_embeds = test_df_w_embeds.groupby([\"id\"]).mean()\n",
    "test_user_embeds = test_df_w_embeds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d608c8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "nkmeans = 16\n",
    "train_preds = []\n",
    "test_preds = []\n",
    "\n",
    "for i in tqdm(range(nkmeans)):\n",
    "    step = feats.shape[1] // nkmeans\n",
    "    kmeans = KMeans(n_clusters=6, random_state=RANDOM_STATE, n_init=\"auto\")\n",
    "    train_pred = kmeans.fit_predict(train_user_embeds[:, i * step : (i + 1) * step])\n",
    "    test_pred = kmeans.predict(test_user_embeds[:, i * step : (i + 1) * step])\n",
    "\n",
    "    train_preds.append(train_pred)\n",
    "    test_preds.append(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f20e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_km = np.hstack([x[..., None] for x in train_preds])\n",
    "test_km = np.hstack([x[..., None] for x in test_preds])\n",
    "\n",
    "train_km_with_id = np.hstack([train_df.iloc[::3,][\"id\"].values[..., None], train_km])\n",
    "test_km_with_id = np.hstack([test_df_w_embeds.index.values[..., None], test_km])\n",
    "\n",
    "train_df_km = pd.DataFrame(\n",
    "    train_km_with_id,\n",
    "    columns=[\n",
    "        \"id\",\n",
    "    ]\n",
    "    + [f\"cluster_{i}\" for i in range(nkmeans)],\n",
    ")\n",
    "test_df_km = pd.DataFrame(\n",
    "    test_km_with_id,\n",
    "    columns=[\n",
    "        \"id\",\n",
    "    ]\n",
    "    + [f\"cluster_{i}\" for i in range(nkmeans)],\n",
    ")\n",
    "\n",
    "train_merged = pd.merge(train_df, train_df_km, left_on=\"id\", right_on=\"id\", how=\"left\")\n",
    "test_merged = pd.merge(test_df, test_df_km, left_on=\"id\", right_on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371af6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.to_parquet(\"data/train_cluster_kmeans.pqt\")\n",
    "test_merged.to_parquet(\"data/test_cluster_kmeans.pqt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c396c4c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710522b3",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b141ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.15\n",
    "\n",
    "train = train_df\n",
    "unique_ids = train[\"id\"].unique()\n",
    "np.random.shuffle(unique_ids)\n",
    "\n",
    "ids_and_clusters = train[train[\"date\"] == \"month_3\"][\n",
    "    [\"id\", \"end_cluster\"]\n",
    "].drop_duplicates()\n",
    "train_ids, test_ids, _, _ = train_test_split(\n",
    "    ids_and_clusters[\"id\"],\n",
    "    ids_and_clusters[\"end_cluster\"],\n",
    "    stratify=ids_and_clusters[\"end_cluster\"],\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    ")\n",
    "dataset_train = train[train[\"id\"].isin(train_ids)]\n",
    "dataset_val = train[train[\"id\"].isin(test_ids)]\n",
    "\n",
    "y_train = dataset_train[target]\n",
    "y_val = dataset_val[target]\n",
    "\n",
    "f_train = feats[:600000][train[\"id\"].isin(train_ids)]\n",
    "f_val = feats[:600000][train[\"id\"].isin(test_ids)]\n",
    "\n",
    "le = LabelEncoder().fit(y_train)\n",
    "y_train_enc = le.transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "\n",
    "input_size = f_train.shape[1]\n",
    "output_size = len(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6ed18",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierPyTorch(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_size),\n",
    "        )\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e856a",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8623ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 1500\n",
    "batch_size = 8192\n",
    "lr = 2e-4\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a5b4f",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c878159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 51/1500 [00:08<03:54,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1500]\n",
      "Training Loss: 0.9946, Validation Loss: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 101/1500 [00:16<03:40,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1500]\n",
      "Training Loss: 0.9596, Validation Loss: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 151/1500 [00:23<03:32,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/1500]\n",
      "Training Loss: 0.9370, Validation Loss: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 201/1500 [00:31<03:20,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/1500]\n",
      "Training Loss: 0.9215, Validation Loss: 0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 251/1500 [00:39<03:21,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/1500]\n",
      "Training Loss: 0.9115, Validation Loss: 0.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 301/1500 [00:47<03:13,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/1500]\n",
      "Training Loss: 0.9041, Validation Loss: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 351/1500 [00:55<02:56,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [350/1500]\n",
      "Training Loss: 0.8980, Validation Loss: 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 401/1500 [01:02<02:56,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/1500]\n",
      "Training Loss: 0.8931, Validation Loss: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 451/1500 [01:10<02:49,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [450/1500]\n",
      "Training Loss: 0.8893, Validation Loss: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 501/1500 [01:18<02:41,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/1500]\n",
      "Training Loss: 0.8882, Validation Loss: 0.8920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 551/1500 [01:26<02:25,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [550/1500]\n",
      "Training Loss: 0.8835, Validation Loss: 0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 601/1500 [01:34<02:18,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [600/1500]\n",
      "Training Loss: 0.8821, Validation Loss: 0.8910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 651/1500 [01:41<02:10,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [650/1500]\n",
      "Training Loss: 0.8800, Validation Loss: 0.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 701/1500 [01:49<02:01,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [700/1500]\n",
      "Training Loss: 0.8789, Validation Loss: 0.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 751/1500 [01:57<02:01,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [750/1500]\n",
      "Training Loss: 0.8764, Validation Loss: 0.8840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 801/1500 [02:05<01:52,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [800/1500]\n",
      "Training Loss: 0.8751, Validation Loss: 0.8823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 851/1500 [02:13<01:44,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [850/1500]\n",
      "Training Loss: 0.8742, Validation Loss: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 901/1500 [02:20<01:39,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [900/1500]\n",
      "Training Loss: 0.8729, Validation Loss: 0.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 951/1500 [02:28<01:25,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [950/1500]\n",
      "Training Loss: 0.8724, Validation Loss: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1001/1500 [02:36<01:20,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/1500]\n",
      "Training Loss: 0.8709, Validation Loss: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1051/1500 [02:44<01:12,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1050/1500]\n",
      "Training Loss: 0.8700, Validation Loss: 0.8819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1101/1500 [02:52<01:05,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1100/1500]\n",
      "Training Loss: 0.8694, Validation Loss: 0.8804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1151/1500 [03:00<00:55,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1150/1500]\n",
      "Training Loss: 0.8685, Validation Loss: 0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1201/1500 [03:08<00:47,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1200/1500]\n",
      "Training Loss: 0.8678, Validation Loss: 0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1251/1500 [03:15<00:39,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1250/1500]\n",
      "Training Loss: 0.8669, Validation Loss: 0.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1301/1500 [03:23<00:31,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1300/1500]\n",
      "Training Loss: 0.8664, Validation Loss: 0.8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1351/1500 [03:31<00:24,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1350/1500]\n",
      "Training Loss: 0.8662, Validation Loss: 0.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1401/1500 [03:39<00:15,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1400/1500]\n",
      "Training Loss: 0.8657, Validation Loss: 0.8780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1451/1500 [03:47<00:07,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1450/1500]\n",
      "Training Loss: 0.8648, Validation Loss: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [03:55<00:00,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1500/1500]\n",
      "Training Loss: 0.8649, Validation Loss: 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifierPyTorch(input_size, output_size).to(DEVICE)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.998)\n",
    "\n",
    "f_train_tensor = torch.tensor(f_train, dtype=torch.float32).to(DEVICE)\n",
    "y_train_tensor = torch.tensor(y_train_enc, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "f_val_tensor = torch.tensor(f_val, dtype=torch.float32).to(DEVICE)\n",
    "y_val_tensor = torch.tensor(y_val_enc, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(max_iter)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(0, len(f_train_tensor), batch_size):\n",
    "        x_batch = f_train_tensor[i : i + batch_size]\n",
    "        y_batch = y_train_tensor[i : i + batch_size]\n",
    "\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    epoch_loss = running_loss / len(f_train_tensor)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:  # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0.0\n",
    "            for i in range(0, len(f_val_tensor), batch_size):\n",
    "                x_val_batch = f_val_tensor[i : i + batch_size]\n",
    "                y_val_batch = y_val_tensor[i : i + batch_size]\n",
    "\n",
    "                outputs = model(x_val_batch)\n",
    "                loss = criterion(outputs, y_val_batch)\n",
    "                valid_loss += loss.item() * x_val_batch.size(0)\n",
    "\n",
    "            epoch_val_loss = valid_loss / len(f_val_tensor)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{max_iter}]\")\n",
    "        print(f\"Training Loss: {epoch_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917574e9",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "606ee1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_tensors = []\n",
    "for i in range(0, len(f_val_tensor), batch_size):\n",
    "    x_val_batch = f_val_tensor[i : i + batch_size]\n",
    "    y_val_batch = y_val_tensor[i : i + batch_size]\n",
    "\n",
    "    outputs = model(x_val_batch)\n",
    "    y_pred_proba_tensors.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed067227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_roc_auc(y_true, y_pred, labels, weights_dict):\n",
    "    unnorm_weights = np.array([weights_dict[label] for label in labels])\n",
    "    weights = unnorm_weights / unnorm_weights.sum()\n",
    "    classes_roc_auc = roc_auc_score(\n",
    "        y_true, y_pred, labels=labels, multi_class=\"ovr\", average=None\n",
    "    )\n",
    "    return sum(weights * classes_roc_auc), classes_roc_auc\n",
    "\n",
    "\n",
    "cluster_weights = pd.read_excel(\"cluster_weights.xlsx\").set_index(\"cluster\")\n",
    "weights_dict = cluster_weights[\"unnorm_weight\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ac82b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8951914936208778,\n",
       " array([0.89255291, 0.89447621, 0.86742571, 0.90845865, 0.88565006,\n",
       "        0.94740019, 0.88652493, 0.87224966, 0.86525395, 0.95808388,\n",
       "        0.86442687, 0.87320917, 0.86953557, 0.98864159, 0.94609204,\n",
       "        0.84453281, 0.91684849]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = torch.concat(y_pred_proba_tensors).softmax(1).detach().cpu().numpy()\n",
    "weighted_roc_auc(y_val, y_pred_proba, le.classes_, weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfLFjyYHNTE4",
   "metadata": {
    "id": "cfLFjyYHNTE4"
   },
   "source": [
    "## Прогноз на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pUpqu4ueNdTO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "pUpqu4ueNdTO",
    "outputId": "70b06bc1-8126-4d53-9d31-2d09078d74ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>{α}</td>\n",
       "      <td>{α}</td>\n",
       "      <td>{α}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200001</th>\n",
       "      <td>{α}</td>\n",
       "      <td>{α}</td>\n",
       "      <td>{α}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>{other}</td>\n",
       "      <td>{other}</td>\n",
       "      <td>{other}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "date    month_4  month_5  month_6\n",
       "id                               \n",
       "200000      {α}      {α}      {α}\n",
       "200001      {α}      {α}      {α}\n",
       "200002  {other}  {other}  {other}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.pivot(index=\"id\", columns=\"date\", values=\"start_cluster\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D7hcKFpa042B",
   "metadata": {
    "id": "D7hcKFpa042B"
   },
   "source": [
    "Для того, чтобы сделать прогноз на тестовой выборке, нужно заполнить стартовый кластер. </br>\n",
    "В качестве базового подхода заполним все стартовые кластеры, самым популярным кластером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efc8b64a-86db-4564-af7b-be649612df82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T11:36:12.303553Z",
     "iopub.status.busy": "2024-02-15T11:36:12.302964Z",
     "iopub.status.idle": "2024-02-15T11:36:12.337469Z",
     "shell.execute_reply": "2024-02-15T11:36:12.336438Z",
     "shell.execute_reply.started": "2024-02-15T11:36:12.303513Z"
    },
    "id": "efc8b64a-86db-4564-af7b-be649612df82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"submissions/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1qVgADkI1MnS",
   "metadata": {
    "id": "1qVgADkI1MnS"
   },
   "source": [
    "Для тестовой выборки будем использовать только последний месяц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0bd8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_m_test_df = feats[600000:][test_df[\"date\"] == \"month_6\"]\n",
    "\n",
    "y_pred_proba_tensors = []\n",
    "test_tensor = torch.tensor(last_m_test_df).to(torch.float32).to(DEVICE)\n",
    "for i in range(0, len(test_tensor), batch_size):\n",
    "    x_val_batch = test_tensor[i : i + batch_size]\n",
    "\n",
    "    outputs = model(x_val_batch)\n",
    "    y_pred_proba_tensors.append(outputs)\n",
    "\n",
    "test_pred_proba = torch.concat(y_pred_proba_tensors).softmax(1).detach().cpu().numpy()\n",
    "test_pred_proba_df = pd.DataFrame(test_pred_proba, columns=le.classes_)\n",
    "sorted_classes = sorted(test_pred_proba_df.columns.to_list())\n",
    "test_pred_proba_df = test_pred_proba_df[sorted_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "xUa5e3c4UcSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUa5e3c4UcSe",
    "outputId": "dbfc0bd8-61c2-44c5-f56c-8031950cf2e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 17)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "QqDRm_FB1oWF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "QqDRm_FB1oWF",
    "outputId": "19fec5f6-7403-48db-c49a-e9b30f481e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>{other}</th>\n",
       "      <th>{}</th>\n",
       "      <th>{α, β}</th>\n",
       "      <th>{α, γ}</th>\n",
       "      <th>{α, δ}</th>\n",
       "      <th>{α, ε, η}</th>\n",
       "      <th>{α, ε, θ}</th>\n",
       "      <th>{α, ε, ψ}</th>\n",
       "      <th>{α, ε}</th>\n",
       "      <th>{α, η}</th>\n",
       "      <th>{α, θ}</th>\n",
       "      <th>{α, λ}</th>\n",
       "      <th>{α, μ}</th>\n",
       "      <th>{α, π}</th>\n",
       "      <th>{α, ψ}</th>\n",
       "      <th>{α}</th>\n",
       "      <th>{λ}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010447</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.036975</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>6.347711e-06</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.879300</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012657</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>5.159997e-07</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.304621</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    {other}        {}    {α, β}    {α, γ}    {α, δ}  {α, ε, η}  {α, ε, θ}  \\\n",
       "0  0.010447  0.011041  0.036975  0.028700  0.002776   0.000126   0.000576   \n",
       "1  0.012657  0.669136  0.000862  0.001895  0.000381   0.000119   0.000105   \n",
       "\n",
       "   {α, ε, ψ}    {α, ε}    {α, η}    {α, θ}    {α, λ}    {α, μ}        {α, π}  \\\n",
       "0   0.000045  0.007295  0.007025  0.010355  0.000500  0.003733  6.347711e-06   \n",
       "1   0.000006  0.000797  0.007721  0.001000  0.000027  0.000432  5.159997e-07   \n",
       "\n",
       "     {α, ψ}       {α}       {λ}  \n",
       "0  0.001099  0.879300  0.000001  \n",
       "1  0.000223  0.304621  0.000017  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_proba_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6fbe390-7b56-45a9-8e5b-ab43f9bb7dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T23:12:01.294283Z",
     "iopub.status.busy": "2024-02-14T23:12:01.293888Z",
     "iopub.status.idle": "2024-02-14T23:12:01.382141Z",
     "shell.execute_reply": "2024-02-14T23:12:01.381647Z",
     "shell.execute_reply.started": "2024-02-14T23:12:01.294266Z"
    },
    "id": "a6fbe390-7b56-45a9-8e5b-ab43f9bb7dfc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission_df[sorted_classes] = test_pred_proba_df\n",
    "sample_submission_df.to_csv(\"mlp_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
